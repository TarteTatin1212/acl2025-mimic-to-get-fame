# You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations
This software project accompanies the research paper, [You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations](https://aclanthology.org/2025.findings-acl.599/). **This paper has been accepted to ACL 2025 Findings.**


<p align="center">
  <img src="assets/mimic_architecture.png" alt="MIMIC Architecture" width="800px">
</p>

## ğŸ¯ The Challenge

Meeting summarization research suffers from severe data scarcity:
- **Privacy concerns** limit real meeting data collection
- **Existing datasets** (AMI, ICSI, QMSum) cover narrow scenarios
- **Non-English resources** are extremely rare
- **Current synthetic methods** fail to capture authentic group dynamics

## ğŸ¬ Our Solution: MIMIC Framework

MIMIC (Multi-agent IMItation of Conversations) is a movie-production-inspired framework that orchestrates psychologically grounded LLM agents to generate realistic meeting transcripts.

### Key Features
- **7-stage pipeline**: Pre-production â†’ Production â†’ Post-production
- **Psychology-based agents**: Each participant has unique behaviors, expertise, and speaking styles
- **Non-omniscient design**: Agents only know their assigned knowledge portions
- **Dynamic interactions**: Natural interruptions, topic evolution, and role changes


## ğŸ“Š FAME Dataset

Generated using MIMIC, FAME (FAke MEetings) provides:
- **800 meetings** (500 English, 300 German)
- **14 meeting types** (brainstorming, decision-making, strategic planning, etc.)
- **28 topic domains** from Wikipedia
- **3,200+ unique participants** with psychological profiles
- **Quality annotations** for authenticity and difficulty

## ğŸ”¬ Key Results

### Meeting Authenticity

<div align="center">

| Metric | FAME-EN | FAME-DE | AMI | ICSI | WPCP | QMSum |
|:------:|:-------:|:-------:|:---:|:----:|:----:|:-----:|
| **Coherence** | 4.5Â±0.00 | 4.5Â±0.18 | 4.5Â±0.36 | 3.5Â±0.36 | 4.5Â±0.00 | 4.5Â±0.73 |
| **Consistency** | 4.5Â±0.07 | 4.5Â±0.09 | 4.5Â±0.68 | 3.5Â±0.87 | 4.5Â±0.38 | 4Â±0.59 |
| **Interestingness** | 4.5Â±0.13 | 4.5Â±0.23 | 4Â±0.68 | 3Â±0.87 | 4Â±0.38 | 4Â±0.77 |
| **Naturalness** | 4.5Â±0.12 | 4Â±1.37 | 4.5Â±0.55 | 4.5Â±0.82 | 5Â±0.00 | 4.5Â±0.90 |

*Values are MedianÂ±Std on a 1-5 scale. Higher is better.*

</div>

- **Naturalness**: 4.5/5 (matches real meetings)
- **Behavioral authenticity**: Closely aligns with human expectations
- **Information density**: Captures real meeting challenges

### Transcript Challenges

<div align="center">

| Challenge | FAME-EN | FAME-DE | QMSum | AMI | ICSI |
|:---------|:-------:|:-------:|:-----:|:---:|:----:|
| **Spoken language** | 3Â±0.49 | 3Â±0.54 | 3Â±1.35 | 4Â±0.22 | 3Â±0.70 |
| **Speaker dynamics** | 2Â±0.62 | 2Â±0.73 | 3Â±0.91 | 4Â±0.66 | 3Â±0.70 |
| **Coreference** | 2Â±0.74 | 3Â±0.80 | 2Â±0.90 | 2Â±0.76 | 2Â±1.07 |
| **Implicit context** | 4Â±0.16 | 4Â±0.18 | 0Â±0.85 | 0Â±0.00 | 2Â±0.97 |
| **Information density** | 4Â±0.27 | 4Â±0.00 | 2.5Â±0.88 | 3Â±0.55 | 2Â±0.57 |

*Values are MedianÂ±Std on a 1-5 scale. Higher indicates more difficulty.*

</div>

### Model Performance on FAME

<div align="center">

| Model | R-1 | R-2 | R-L | BERTScore | Omission | Hallucination |
|:------|:---:|:---:|:---:|:---------:|:--------:|:-------------:|
| **GPT-4o** | 39.68Â±5.73 | 8.43Â±3.45 | 29.98Â±4.88 | 63.80Â±3.11 | 4Â±0.16 | 4Â±0.98 |
| **Gemini 1.5** | 38.82Â±5.79 | 8.96Â±3.50 | 27.81Â±4.18 | 63.66Â±2.49 | 4Â±0.31 | 4Â±1.40 |
| **DeepSeek-R1** | 33.18Â±7.38 | 8.07Â±3.33 | 23.16Â±5.98 | 63.16Â±3.37 | 4Â±0.48 | 4Â±1.81 |
| **Llama 3.3** | 40.35Â±5.46 | 8.62Â±3.18 | 29.45Â±3.67 | 63.53Â±2.72 | 4Â±0.31 | 4Â±1.02 |

*ROUGE scores (0-100), MESA scores (1-5 Likert). For MESA, lower is better.*

</div>

- FAME reveals persistent LLM context-handling issues
- Omission errors increase from 3/5 (QMSum) to 4/5 (FAME)
- Fine-tuning on FAME improves real meeting summarization



### Behavioral Pattern
Evaluation of the social behavior in the meetings shows that FAME aligns closely with both QMSum and crowdsourced baselines.


<p align="center">
  <img src="assets/behavior_patterns.png" alt="Behavior Patterns" width="500px">
</p>

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/FKIRSTE/acl2025-mimic-to-get-fame.git
cd acl2025-mimic-to-get-fame

# Install dependencies
pip install -r requirements.txt

# Generate meetings on a specific domain (optional)
python generate_eng.py --domains "Scientific Topics"

```

## ğŸ“ Repository Structure
```
fame_dataset/
â”œâ”€â”€ English/                  # English meeting transcripts (multiple types, domains, topics)
â”‚   â””â”€â”€ scenes_evolution/     # Scene evolution data
â”œâ”€â”€ German/                   # German meeting transcripts (multiple types, domains, topics)
â”‚   â””â”€â”€ scenes_evolution/     # Scene evolution data
â”œâ”€â”€ schema/                   # Meeting schema (JSON)
â”‚   â””â”€â”€ meeting_schema.json
â”‚
README_DATASET.md             # Dataset documentation
DATA_ACCESS.md                # Data access instructions
metadata.yaml                 # Metadata for dataset

mimic_pipeline/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config_gpt.json           # LLM configuration
â”œâ”€â”€ generator.py              # Main generator
â”œâ”€â”€ generator_eng.py          # English generator
â”œâ”€â”€ generator_de.py           # German generator
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ basics/                   # Core pipeline scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ script_multiagent_discussion.py
â”‚   â””â”€â”€ scripts/
â”œâ”€â”€ misc/                     # Evaluation and aggregation scripts
â”‚   â”œâ”€â”€ agg_meetings_and_metrics.py
â”‚   â”œâ”€â”€ compute_meeting_stats.py
â”‚   â”œâ”€â”€ evaluate_meeting_challenges.py
â”‚   â”œâ”€â”€ ngram_overlap.py
â”‚   â”œâ”€â”€ noises.py
â”‚   â”œâ”€â”€ sstories.csv
â”‚   â”œâ”€â”€ summary_assessment.py
â”‚   â”œâ”€â”€ test_evaluations.py
â”‚   â”œâ”€â”€ test_meeting.py
â”‚   â”œâ”€â”€ test_noises.py
â”‚   â””â”€â”€ pmc_articles_md_txt/
â”œâ”€â”€ output/                   # Generated corpora will go here
â”‚   â””â”€â”€ final_corpora/
â”œâ”€â”€ pipeline/                 # Meeting generation and evaluation modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ discussion_protocol.py
â”‚   â”œâ”€â”€ meeting_evaluator.py
â”‚   â”œâ”€â”€ meeting_generator.py
â”‚   â”œâ”€â”€ meeting_plan_generator.py
â”‚   â”œâ”€â”€ save_content.py
â”‚   â”œâ”€â”€ summary_generator.py
â”‚   â”œâ”€â”€ wiki_articles_de.json
â”‚   â”œâ”€â”€ wiki_articles_eng.json
â”‚   â”œâ”€â”€ wiki_reader.py
â”‚   â””â”€â”€ wikiscrape.py
```

## ğŸ­ Example: From Wikipedia to Meeting
<details><summary>Click to see how "Pandemics" article becomes a meeting</summary>

**Input**: Wikipedia article on Pandemics
**Stage 1-3**: Extract topics â†’ Cast participants â†’ Create agenda
**Stage 4**: Multi-agent conversation

```
Â»Virologist: According to the latest research, CEPI's initiative to condense vaccine
development timelines to 100 days is groundbreaking! However, we need a comprehensive
approach beyond rapid vaccine development.

Â»Public Health Policy Maker: Absolutely! We must ensure diagnostics and therapies are
available during vaccine rollout...
````

**Stage 5-7**: Quality assurance â†’ Special effects â†’ Final polish
</details>


## ğŸ“ Citation
```
bibtex@inproceedings{kirstein-etal-2025-need,
  title={You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with Multi-Agent Conversations},
  author={Kirstein, Frederic and Khan, Muneeb and Wahle, Jan Philip and Ruas, Terry and Gipp, Bela},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={11482--11525},
  year={2025},
  address={Vienna, Austria},
  publisher={Association for Computational Linguistics}
}
````

<p align="center">
  <b>Questions?</b> Open an issue or contact <a href="mailto:kirstein@gipplab.org">kirstein@gipplab.org</a>
</p>